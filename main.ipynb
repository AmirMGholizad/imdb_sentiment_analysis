{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 12:33:01.758865: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 12:33:01.761724: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 12:33:01.794135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-21 12:33:01.794164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-21 12:33:01.795165: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-21 12:33:01.802050: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 12:33:01.802504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 12:33:02.454876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import functions as fs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf;\n",
    "from keras.models import Sequential;\n",
    "from keras.layers import Dense, Dropout, Activation;\n",
    "from keras.preprocessing.text import Tokenizer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_words = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access and download data\n",
    "data = tf.keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data(path=\"imdb.npz\",\n",
    "                                                     num_words=num_words,\n",
    "                                                     skip_top=10,\n",
    "                                                     maxlen=None,\n",
    "                                                     seed=113,\n",
    "                                                     start_char=1,\n",
    "                                                     oov_char=2,\n",
    "                                                     index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_train, X_test, Y_train, Y_test = fs.imdb_preprocessing(x_train, x_test,\n",
    "                                                         y_train, y_test,\n",
    "                                                         num_words, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               512512    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578434 (2.21 MB)\n",
      "Trainable params: 578434 (2.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model1\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, input_shape=(num_words,)))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(num_classes))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3803 - accuracy: 0.8322\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3164 - accuracy: 0.8642\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3072 - accuracy: 0.8690\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2966 - accuracy: 0.8742\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2893 - accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2777 - accuracy: 0.8809\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2640 - accuracy: 0.8877\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2452 - accuracy: 0.8947\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2200 - accuracy: 0.9066\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1830 - accuracy: 0.9231\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4090 - accuracy: 0.8526\n",
      "Model1's accuracy:  0.8525599837303162\n"
     ]
    }
   ],
   "source": [
    "# fit and evaluate model1\n",
    "model1.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=1)\n",
    "score1 = model1.evaluate(X_test, Y_test)\n",
    "print(\"Model1's accuracy: \", score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               512512    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513538 (1.96 MB)\n",
      "Trainable params: 513538 (1.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model2\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu', input_dim=num_words))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 3s - loss: 0.3952 - accuracy: 0.8262 - val_loss: 0.3332 - val_accuracy: 0.8597 - 3s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 3s - loss: 0.3187 - accuracy: 0.8702 - val_loss: 0.3340 - val_accuracy: 0.8611 - 3s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 3s - loss: 0.2893 - accuracy: 0.8891 - val_loss: 0.3520 - val_accuracy: 0.8618 - 3s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 3s - loss: 0.2637 - accuracy: 0.9062 - val_loss: 0.3802 - val_accuracy: 0.8605 - 3s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 3s - loss: 0.2283 - accuracy: 0.9250 - val_loss: 0.4087 - val_accuracy: 0.8594 - 3s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 3s - loss: 0.1975 - accuracy: 0.9399 - val_loss: 0.4624 - val_accuracy: 0.8592 - 3s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 3s - loss: 0.1677 - accuracy: 0.9522 - val_loss: 0.5000 - val_accuracy: 0.8591 - 3s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 3s - loss: 0.1363 - accuracy: 0.9652 - val_loss: 0.5694 - val_accuracy: 0.8588 - 3s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 4s - loss: 0.1088 - accuracy: 0.9720 - val_loss: 0.6178 - val_accuracy: 0.8570 - 4s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 3s - loss: 0.0881 - accuracy: 0.9783 - val_loss: 0.6961 - val_accuracy: 0.8564 - 3s/epoch - 4ms/step\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4090 - accuracy: 0.8526\n",
      "Model2's accuracy:  0.8525599837303162\n"
     ]
    }
   ],
   "source": [
    "# fit and evaluate model2\n",
    "model2.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test), verbose=2)\n",
    "score2 = model1.evaluate(X_test, Y_test)\n",
    "print(\"Model2's accuracy: \", score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your review was: I loved the movie! It was great!\n",
      "\n",
      "\n",
      "Predictiong with model1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "This review was Positive!\n",
      "\n",
      "\n",
      "Predictiong with model2\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "This review was Positive!\n"
     ]
    }
   ],
   "source": [
    "# make predictions with both models\n",
    "# write any reviews\n",
    "review = \"I loved the movie! It was great!\"\n",
    "print(\"Your review was: \" + review)\n",
    "\n",
    "print(\"\\n\\nPredictiong with model1\")\n",
    "fs.imdb_predict(model1, data, review, num_words)\n",
    "\n",
    "print(\"\\n\\nPredictiong with model2\")\n",
    "fs.imdb_predict(model2, data, review, num_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
